{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from itertools import zip_longest\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import muscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.modules['muscope'].__file__)\n",
    "muscope_loader_dp = os.path.dirname(sys.modules['muscope'].__file__)\n",
    "downloads_dp = os.path.join(muscope_loader_dp, 'downloads')\n",
    "dyhrman_xls_fp = os.path.join(downloads_dp, 'Dyhrman_HL2A_RNAdiel_seq_assoc_data_v4.xls')\n",
    "\n",
    "print(dyhrman_xls_fp)\n",
    "os.path.exists(dyhrman_xls_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip rows 0, 2\n",
    "# row 1 becomes row 0\n",
    "# now the header is row 0\n",
    "core_attr_plus_data_df = pd.read_excel(\n",
    "    dyhrman_xls_fp,\n",
    "    sheet_name='core attributes + data',\n",
    "    skiprows=(0,2)\n",
    ")\n",
    "##print(core_attr_plus_data_df.head())\n",
    "\n",
    "# there are 4 seq_names for each sample name\n",
    "# the first 2 seq_names are paired-end reads e.g. \n",
    "#   SM178_S9_L001_R1_001.fastq.gz and SM178_S9_L001_R2_001.fastq.gz\n",
    "# the second 2 seq_names are paired-end reads e.g.\n",
    "#   SM226_S9_L005_R1_001.fastq.gz and SM226_S9_L005_R2_001.fastq.gz\n",
    "\n",
    "# parse time strings such as '12:45:00' and '1245'\n",
    "# the first 3 collection times are datetime objects, the remaining collection times are just strings like \"1205\"\n",
    "time_re = re.compile(r'^(?P<hour>\\d{1,2}):?(?P<minute>\\d{1,2})(:(?P<second>)\\d{1,2})?$')\n",
    "\n",
    "for (r1, row1), (r2, row2), (r3, row3), (r4, row4) in grouper(core_attr_plus_data_df.iterrows(), n=4):    \n",
    "    ##print(row1.seq_name)\n",
    "    ##sample_description_column.append(row1.sample_name)  # e.g. insitu_15m_S9C1_rep1\n",
    "    ##sample_description_column.append(row2.sample_name)  # empty\n",
    "    ##sample_description_column.append(row1.sample_name)  # e.g insitu_15m_S9C1_rep1\n",
    "    ##sample_description_column.append(row2.sample_name)  # empty\n",
    "\n",
    "    # convert the strings in collection_time to datetime.time objects\n",
    "    ##print('\"{}\"'.format(row1.collection_time))\n",
    "    collection_time_match = time_re.search(str(row1.collection_time))\n",
    "    core_attr_plus_data_df.loc[row1.name, 'collection_time'] = datetime.time(\n",
    "        hour=int(collection_time_match.group('hour')),\n",
    "        minute=int(collection_time_match.group('minute')))\n",
    "    \n",
    "    # copy attributes from 1st row to 3rd row\n",
    "    core_attr_plus_data_df.loc[row3.name, 0:8] = core_attr_plus_data_df.iloc[row1.name, 0:8]\n",
    "    core_attr_plus_data_df.loc[row3.name, 10:] = core_attr_plus_data_df.iloc[row1.name, 10:]\n",
    "\n",
    "core_attr_plus_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_attr_plus_data_df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
